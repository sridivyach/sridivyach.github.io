
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="Hima Lakkaraju" content="">
    <meta name="Hima Lakkaraju" content="">

    <title>Hima Lakkaraju</title>

    <!-- Nunito Sans font -->
    <link href="https://fonts.googleapis.com/css?family=Nunito+Sans" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Patrick+Hand+SC" rel="stylesheet">
    <!-- Bootstrap core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <!-- Bootstrap theme -->
    <link href="css/bootstrap-theme.min.css" rel="stylesheet">
    <!-- font awesome icons -->
    <link href="css/icon.css" rel="stylesheet">
    <!-- Overriding personal style -->
    <link href="css/style.css" rel="stylesheet">   
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> 
  <script type="text/javascript">
   function visibility_on(id) {
        var e = document.getElementById(id+"_text");
        if(e.style.display == 'none')
            e.style.display = 'block';
        var e = document.getElementById(id+"_img");
        if(e.style.display == 'none')
            e.style.display = 'block';
   }
   function visibility_off(id) {
        var e = document.getElementById(id+"_text");
        if(e.style.display == 'block')
            e.style.display = 'none';
        var e = document.getElementById(id+"_img");
        if(e.style.display == 'block')
            e.style.display = 'none';
   }
   function toggle_visibility(id) {
       var e = document.getElementById(id+"_text");
       if(e.style.display == 'inline')
          e.style.display = 'block';
       else
          e.style.display = 'inline';
       var e = document.getElementById(id+"_img");
       if(e.style.display == 'inline')
          e.style.display = 'block';
       else
          e.style.display = 'inline';
   }
   function toggle_vis(id) {
       var e = document.getElementById(id);
       if (e.style.display == 'none')
           e.style.display = 'inline';
       else
           e.style.display = 'none';
   }
</script>
    <style>
	  	ul.no-bullets {
  				list-style-type: none;
  				margin: 0;
  				padding: 0;
			       }
    </style>
  </head>

  <body>
    <!-- Fixed navbar -->
    <nav class="navbar navbar-default navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="#">Hima Lakkaraju</a>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
            <li><a href="#">Home</a></li>
            <li><a href="#news">News</a></li>	    
            <li><a href="#research">Research</a></li>
	    <li><a href="#students">Advising</a></li>
            <li><a href="#teaching">Teaching</a></li>
	    <li><a href="https://himalakkaraju.github.io/openpositions.html">Open Positions</a></li>
            <!--<li><a href="#papers">Service</a></li>-->
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>

    <div class="container theme-showcase" role="main">
      <div class="row">
	<div class="col-md-3">
	  <h3>Hima Lakkaraju</h3>
	  <img class="img-thumbnail" src="images/hima-2019.jpg" alt="" style="width:70%"/>
	  <br /><br />
	  <h4>Contact</h4>
	<font size="3"><a href="mailto:hlakkaraju@hbs.edu" class="icon fa-envelope"></a> hlakkaraju@hbs.edu<br />
	<font size="3"><a href="mailto:hlakkaraju@seas.harvard.edu" class="icon fa-envelope"></a> hlakkaraju@seas.harvard.edu<br />
	<br>
	<a href="https://www.google.com/maps/place/Morgan+Hall,+15+Harvard+Way,+Boston,+MA+02163/@42.3656487,-71.1235283,13z/data=!4m5!3m4!1s0x89e37760e1889289:0x9bdcdfeb1d014231!8m2!3d42.3667941!4d-71.123931" class="icon fa-building"></a> 442 Morgan Hall <br />
	<a href="https://www.google.com/maps/place/Maxwell-Dworkin,+33+Oxford+St,+Cambridge,+MA+02138/data=!4m2!3m1!1s0x89e37741136f99f3:0xdee244d8cde0c0dc?sa=X&ved=2ahUKEwj5m4CM8OfkAhVyZN8KHZt5AooQ8gEwAHoECAwQAQ" class="icon fa-building"></a> 337 Maxwell Dworkin<br />
	<br>
		<a href="https://en.wikipedia.org/wiki/Himabindu_Lakkaraju" class="icon fa-wikipedia-w"> </a> Wikipedia <br />
	<a href="https://twitter.com/hima_lakkaraju" class="icon fa-twitter"></a> @hima_lakkaraju<br />
	<a href="https://github.com/AI4LIFE-GROUP" class="icon fa-github"></a> lvhimabindu<br />	  </font>
	</div>
	
	<div class="col-md-9">
	  <br /><br />
	  <h3></h3>
	  <font size="3">

<p>I am an <font color="#cc0000">Assistant Professor at Harvard University</font> with appointments in the Business School and the Department of Computer Science. </p> 
<blockquote style=" padding: 10px; background-color: #eeeeee;"><font size="3">
         <p>My research interests lie within the broad area of <font color="#cc0000">trustworthy machine learning</font>. More specifically, my research spans <font color="#cc0000">explainable</font>, <font color="#cc0000">fair</font>,  and <font color="#cc0000">robust</font> ML. I am also very interested in <font color="#cc0000">reinforcement learning</font> and <font color="#cc0000">causal inference</font>.  
		 <p>I develop machine learning tools and techniques which enable human decision makers to make better decisions. More specifically, my research addresses the following fundamental questions pertaining to human and algorithmic decision-making:
	</p>
	<ol>
<li> How to build fair and interpretable models that can aid human decision-making?
<li> How to ensure that models and their explanations are robust to adversarial attacks? 
<li> How to train and evaluate models in the presence of missing counterfactuals?
<li> How to detect and correct underlying biases in human decisions and algorithmic predictions? 
</ol>
<p>These questions have far-reaching implications in domains involving high-stakes decisions such as health care, policy, law, and business. 
<!--My research tackles the above questions by effectively handling the core underlying challenges such as missing counterfactuals and presence of unmeasured confounders.--> 
</p>

	
	</font>
	
</blockquote>
		  <p> I lead the <font color="#cc0000">AI4LIFE</font> research group at Harvard and I recently co-founded the <a href="https://www.trustworthyml.org/">Trustworthy ML Initiative (TrustML)</a> to help lower entry barriers into trustworthy ML and bring together researchers and practitioners working in the field. 
		  </p>
<p>
	My research is being generously supported by <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2008461&HistoricalAwards=false">NSF</a>, <a href="https://research.google/outreach/">Google</a>, <a href="https://www.amazon.science/research-awards/recipients/himabindu-lakkaraju-2020">Amazon</a>, <a href="https://www.jpmorgan.com/technology/artificial-intelligence/research-awards">JP Morgan</a>, <a href="https://www.bayer.com/en/">Bayer</a>, <a href="https://datascience.harvard.edu/">Harvard Data Science Initiative</a>, and <a href="https://d3.harvard.edu/">D^3 Insitute at Harvard</a>. Prior to my stint at Harvard, I received my PhD in Computer Science from Stanford University.
	
</p>
<p>
For more details about me and my research, please check out my <a href="./HimaCV.pdf">CV</a>. <!-- and here is a <a href="./one-pager.pdf">one-pager</a> about my research. -->
</p>
<p>
<font color="#cc0000">NOTE:</font> I am looking for motivated <font color="#cc0000">undergraduate and graduate students as well as postdocs</font> who are broadly interested in trustworthy machine learning and its applications to health care and criminal justice. 
	If you are excited about this line of research and would like to work with me, please <a href="javascript:toggle_vis('contact')">read this</a> before contacting me. 
</p>		  <div id="contact" style="display:none"> 
		  <blockquote style=" padding: 10px; background-color: #EEEEEE;"><font size="3">
                  <p>Thank you for your interest in joining my lab! I am currently recruiting undergraduate, masters, and PhD students as well as postdoctoral fellows. </p>
			  <p>If you are interested in a <i>postdoc</i> position, please see <a href="https://himalakkaraju.github.io/openpositions.html">this page</a> for more details and application process. <!--send me an email with your 
 and a brief description of your research interests. Please use the subject line <font color="#cc0000">"Postdoctoral Fellowship Application"</font> in your email. --> </p> 
		  <p>If you are a <i>current or admitted undergraduate or masters or PhD student at Harvard</i>, please send me an email with your CV and a brief description of your research interests. Please use the subject line <font color="#cc0000">"Interested in Collaboration (Harvard Student)"</font> in your email. 
	  	  </p>
		  If you are <i>not (yet!) a student at Harvard and would like to pursue a PhD under my guidance</i>, <font color="#cc0000">please apply to BOTH the following PhD programs and mention my name in your statements and applications</font>: 
		  <ol>
			  <li> <a href="https://gsas.harvard.edu/programs-of-study/all/business-administration">PhD Program in Technology and Operations Management</a> at Harvard Business School. 
			  </li>
			  <li> <a href="https://www.seas.harvard.edu/computer-science/graduate-programs/how-apply">PhD Program in Computer Science</a> at Harvard SEAS.
			  </li>	  
		  </ol>
		  <p> I have few internship positions available for students who are already doing their PhD in the United States. If this is of interest, please send me an email with your CV and a brief description of your research interests. Please use the subject line <font color="#cc0000">"Internship Position (PhD Student)"</font> in your email. 
			  </p> 
		  <p>
		  Unfortunately, I will not be able to respond to any individual emails about admissions to masters or PhD programs. 
	 	  </p>
		  <!--<p> I am also open to research collaborations with students and faculty both within Harvard and elsewhere. If you are interested in collaborating with me and my group, please send me an email with a brief description of your research interests and background. Please do not forget to include a link to your webpage and/or your CV. </p>
	        -->  
		</blockquote>
	          </div>
		  </font>

	  
	</div>
	<font size="3">
      </div>

      <div class="page-header" id="news"><h3>Selected Achievements</h3></div>
      <div class="row">
        <div class="col-md-12">
          <ul>
		  <li> <a href="https://www.jpmorgan.com/technology/artificial-intelligence/research-awards">JP Morgan Faculty Research Award</a>, 2022 </li>
		  <li> Best Paper Award, <a href="https://icml.cc/virtual/2021/workshop/8358">ICML Workshop on Interpretable ML in Healthcare</a>, 2022 </li>
		  <li> Released the first version of <a href="https://open-xai.github.io/">OpenXAI</a>, a light-weight open source library to evaluate and benchmark post hoc explanation methods, 2022 </li>
		  <li> <a href="https://www.amazon.science/research-awards/recipients/himabindu-lakkaraju-2020">Amazon Research Award</a>, 2021 </li>
		  <li> <a href="https://sites.google.com/view/aiforsocialgoodworkshop/2021-projects">Google AI for Social Good Research Award</a>, 2021 </li>
		  <li> Best Paper Runner Up, <a href="https://icml.cc/virtual/2021/workshop/8363">ICML Workshop on Algorithmic Recourse</a>, 2021 </li>
		  <li> <a href="https://research.google/outreach/research-scholar-program/recipients/">Google Research Award</a>, 2020 </li>
		  <li> <a href="https://prizes.fas.harvard.edu/hoopes-prize">Hoopes prize</a> for undergraduate thesis mentoring, Harvard University, 2020 </li>
		  <li> Co-founded <a href="https://www.trustworthyml.org/">Trustworthy ML Initiative</a> to enable easy access to resources on trustworthy ML & to build a community of researchers/practitioners, 2020 </li>
		  <li> Named one of the world's <a href="https://www.innovatorsunder35.com/the-list/himabindu-lakkaraju/">35 innovators under 35 by MIT Tech Review</a>, 2019 </li>
		  <li> Named one of the world's <a href="https://www.vanityfair.com/news/2019/10/future-innovators-index-2019">top innovators to watch by Vanity Fair</a>, 2019 </li>
		  <li> Selected for the prestigious Cowles fellowship by Yale University, 2018 </li>
		  <li> INFORMS Best Data Mining Paper Award, 2017 </li>
		  <li> <a href="https://www.microsoft.com/en-us/research/blog/dissertation-grant-program-winners/">Microsoft Research Dissertation Grant</a>, 2017 </li>
		  <li> Named a <a href="http://risingstars.ece.cmu.edu/himabindu-lakkaraju/">Rising Star in Computer Science</a>, 2016 </li>
		  <li> <a href="https://buildyourfuture.withgoogle.com/programs"> Google Anita Borg Fellowship </a>, 2015 </li>
		  <li> <a href="https://vpge.stanford.edu/fellowships-funding/current-vpge-fellows/all-2013">Stanford Graduate Fellowship</a>, 2013-17 </li>
		  <li> Eminence and Excellence Award, IBM Research, 2012 </li>
		  <li> Research Division Award, IBM Research, 2012 </li>
		  <li> Best Paper Award, <a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611972818.43">SIAM International Conference on Data Mining</a>, 2011 </li> 
          </ul>
        </div>
      </div>
 
      <div class="page-header" id="news"><h3>Upcoming and Recent Talks</h3></div>
      <div class="row">
        <div class="col-md-12">
          <ul>
		  <li> <date>11.2022</date> <a href="https://ml4health.github.io/2022/">Machine Learning for Health (ML4H) Workshop</a> Co-located with NeurIPS, 2022 </li>
		  <li> <date>08.2022</date> <a href="https://aisafety.stanford.edu/">Stanford Center for AI Safety</a> </li>
		  <li> <date>08.2022</date> <a href="https://www.amazon.science/tag/alexa">Amazon Alexa</a> Rising Star Speaker Series </li>
		  <li> <date>06.2022</date> <a href="https://xai4cv.github.io/workshop">CVPR Workshop on Explainable AI for Computer Vision</a> </li>
		  <li> <date>05.2022</date> <a href="https://pair2struct-workshop.github.io/">ICLR Workshop on Privacy, Accountability, Interpretability, Robustness, Reasoning on Structured Data</a> </li>
		  <li> <date>05.2022</date> Keynote at <a href="https://aihealth.ischool.utexas.edu/AIHealthWWW2022/index.html">WWW Workshop on Explainable AI in Health</a> </li>
		  <li> <date>05.2022</date> Fiddler AI Fireside Chat </li>
		  <li> <date>04.2022</date> <a href="https://finreglab.org/artificial-intelligence-and-the-economy-charting-a-path-for-responsible-and-inclusive-ai-2">AI and the Economy</a> (U.S. Department of Commerce, National Institute of Standards and Technology, Stanford HAI, and the FinRegLab) </li>
		  <li> <date>04.2022</date> <a href="https://hai.stanford.edu/events/2022-hai-spring-conference-key-advances-artificial-intelligence">Stanford Human-Centered Artificial Intelligence (HAI) Conference</a> </li>
		  <li> <date>04.2022</date> <a href="https://digitaleconomy.stanford.edu/event/seminar-series-with-hima-lakkaraju/">Stanford Digital Econ Seminar</a> </li>
		  <li> <date>03.2022</date> University of Southern California </li>
		  <li> <date>12.2021</date> <a href="https://www.afciworkshop.org/">NeurIPS Workshop on Algorithmic Fairness through the Lens of Causality and Robustness</a> </li>
		  <li> <date>12.2021</date> <a href="https://xai4debugging.github.io/">NeurIPS Workshop on Explainable AI Approaches for Debugging and Diagnosis</a> </li>
		  <li> <date>12.2021</date> <a href="https://neurips.cc/virtual/2021/workshop/21835">NeurIPS Workshop on Human and Machine Decisions</a> </li>
		  <li> <date>12.2021</date> <a href="https://pinlabstechtalkdec21.splashthat.com/">Pinterest Tech Talks -- Distinguished Lecture</a> </li>
		  <li> <date>11.2021</date> Keynote at <a href="https://www.cikm2021.org/programme/keynote-speakers#towards-reliable-and-practicable-algorithmic-recourse">ACM Conference on Information and Knowledge Management</a> </li>
		  <li> <date>11.2021</date> <a href="https://www.nist.gov/news-events/events/2021/10/kicking-nist-ai-risk-management-framework"> NIST AI Risk Management Framework Workshop </a> </li>
		  <li> <date>11.2021</date> <a href="https://get.mccombs.utexas.edu/2021-catt-global-analytics-summit/#lp-pom-block-1164?utm_source=rss&utm_medium=rss&utm_campaign=catt-2021-global-analytics-summit-on-explainable-ai">Global Analytics Summit, University of Texas at Austin</a> </li>
		  <li>
			  <date>10.2021</date> <a href="https://www.fiddler.ai/fiddlers-explainable-ai-summit"> Explainable AI Summit, Fiddler.ai </a>
		  </li> 
		  <li>
			  <date>08.2021</date> <a href="https://www.youtube.com/watch?v=8Ym4oYTd8Fo"> Podcast on Explainability and Fairness in AI with Jay Shah </a>
		  </li> 
		  <li>
			  <date>08.2021</date> Keynote at <a href="https://sites.google.com/view/kdd-mlf-2020/">KDD Workshop on ML for Finance</a> 
		  </li>
		  <li> <date>07.2021</date> <a href="https://aiforgood.itu.int/event/trustworthy-ai-himabindu-lakkaraju/">AI for Good Summit organized by International Telecommunications Union & the United Nations </a> </li>
		  <li> 
			  <date>07.2021</date> <a href="https://sites.google.com/view/imlh2021/">ICML Workshop on Interpretable ML in Healthcare</a> 
		  </li>
		  <li>
			  <date>07.2021</date> <a href="http://www.neurosymbolic.org/events.html"> Neurosym Webinar Series, Jointly Organized by UPenn, MIT, Caltech, and Stanford </a>
		  <!-- <li> 
			  <date>06.2021</date> <a href="http://cvpr2021.thecvf.com/">CVPR Workshop on Responsible Computer Vision</a> 
		  </li>
		  <li>
			  <date>05.2021</date> Keynote at <a href="https://sites.google.com/view/rai-workshop/">ICLR Workshop on Responsible AI</a>
		  </li>
		  <li> 
			  <date>05.2021</date> <a href="https://www.cl.cam.ac.uk/research/ai/meetings/">University of Cambridge</a> 
		  </li>
		  <li>
			  <date>05.2021</date> Guest Lecture at <a href="https://exploreintrosems.stanford.edu/frosh/counterfactuals-science-what-ifs">Stanford University</a>
		  </li>
		  <li>
			  <date>04.2021</date> Invited Tutorial at <a href="https://www.chilconference.org/calendar.html#tab-tutorials">CHIL conference</a>
		  </li>
		  <li>
			  <date>04.2021</date> <a href="https://rss2workshop.github.io/">ASPLOS Workshop on Systems Architecture for Robust, Safe, and Resilient Software</a>
		  </li> 
		  <li>
			  <date>04.2021</date> <a href="https://personal-workshop.com/personal-mlsys-2021/">MLSys Workshop on Personalized Recommender Systems and Algorithms</a>
		  </li> 
		  <li>
			  <date>04.2021</date> <a href="https://www.sri.com/">SRI International</a>
		  </li>
		  <li>
			  <date>04.2021</date> Guest Lecture at <a href="https://projects.iq.harvard.edu/cs288/schedule">AI for Social Impact</a> course at Harvard University
		  </li>
		  <li> 
			  <date>02.2021</date> <a href="https://groups.cs.umass.edu/voicesofds/">Voices of Data Science, UMass Amherst</a> 
		  </li>
		  <li> 
			  <date>01.2021</date> <a href="https://www.cis.mpg.de/events/">Max Planck Symposium on Computing and Society</a> 
		  </li>
          <li>
		  <date>12.2020</date> Guest Lectures in <a href="https://www.cs.cmu.edu/~nihars/teaching/10715-Fa20/index.html">Advanced Machine Learning</a> and <a href="https://haiicmu.github.io/calendar/">Human-AI Interaction</a> Courses at <a href="https://www.cmu.edu/">Carnegie Mellon University</a>
		  
	  </li> -->
          </ul>
        </div>
      </div>
      </font>

      <div class="page-header" id="research"><h3>Research</h3></div>

     <h4>Publications</h4>   
	<font size="3">
	      <ul class="no-bullets">
		      <li>
			      See <a href="https://scholar.google.com/citations?hl=en&user=oWid5PQAAAAJ&view_op=list_works&sortby=pubdate">Google Scholar Page</a> for latest preprints
		      </li>
		      <br />
		      <li>
			      <sup>*</sup> below indicates equal contribution
		      </li>
	      </ul>
	      <br>
	      <ul>
		      <li>
		      <p> Which Explanation Should I Choose? A Function Approximation Perspective to Characterizing Post hoc Explanations
 <br />
			      Tessa Han, Suraj Srinivas, Himabindu Lakkaraju <br />
			      <i></i> Advances in Neural Information Processing Systems (NeurIPS), 2022.<br />
			      <font color="#cc0000">Best Paper Award</font>, ICML Workshop on Interpretable Machine Learning in Healthcare, 2022. <br />
			      <a href="https://arxiv.org/pdf/2206.01254.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
		      <li>
		      <p> Flatten the Curve: Efficiently Training Low-Curvature Neural Networks <br />
			      Suraj Srinivas, Kyle Matoba, Himabindu Lakkaraju, Francois Fleuret <br />
			      <i></i> Advances in Neural Information Processing Systems (NeurIPS), 2022.<br />
			      <a href="https://arxiv.org/pdf/2206.07144.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
		         <li>
		      <p> OpenXAI: Towards a Transparent Evaluation of Model Explanations <br />
			      Chirag Agarwal, Satyapriya Krishna, Eshika Saxena, Martin Pawelczyk, Nari Johnson, Isha Puri, Marinka Zitnik, Himabindu Lakkaraju <br />
			      <i></i> Advances in Neural Information Processing Systems (NeurIPS), 2022.<br />
			      <a href="https://arxiv.org/pdf/2206.11104.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
		      <li>
		      <p> Data Poisoning Attacks on Off-Policy Evaluation Methods <br />
			      Elita Lobo, Harvineet Singh, Marek Petrik, Cynthia Rudin, Himabindu Lakkaraju <br />
			      <i></i> Conference on Uncertainty in Artificial Intelligence (UAI), 2022.<br />
			      <font color="#cc0000"> Oral Presentation [Top 5%] </font> <br />
			      <a href="https://openreview.net/pdf?id=BgbgH_Ls5lc" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
              <li>
		      <p> Exploring Counterfactual Explanations Through the Lens of Adversarial Examples: A Theoretical and Empirical Analysis. <br />
			      Martin Pawelczyk, Chirag Agarwal, Shalmali Joshi, Sohini Upadhyay, Himabindu Lakkaraju <br />
			      <i></i> International Conference on Artificial Intelligence and Statistics (AISTATS), 2022.<br />
			      <a href="https://arxiv.org/pdf/2106.09992.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
	      <li>
		      <p> Probing GNN Explainers: A Rigorous Theoretical and Empirical Analysis of GNN Explanation Methods. <br />
			      Chirag Agarwal, Marinka Zitnik<sup>*</sup>, Himabindu Lakkaraju<sup>*</sup> <br />
			      <i></i> International Conference on Artificial Intelligence and Statistics (AISTATS), 2022.<br />
			      <a href="https://arxiv.org/pdf/2106.09078.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
	      <li>
		      <p> Fairness via Explanation Quality: Evaluating Disparities in the Quality of Post hoc Explanations. <br />
			      Jessica Dai, Sohini Upadhyay, Ulrich Aivodji, Stephen Bach, Himabindu Lakkaraju<br />
			      <i></i> AAAI/ACM Conference on AI, Society, and Ethics (AIES), 2022.<br />
			      <a href="https://arxiv.org/pdf/2205.07277.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>    
	      </li>
	      <li>
		      <p> Towards Robust Off-Policy Evaluation via Human Inputs. <br />
			      Harvineet Singh, Shalmali Joshi, Finale Doshi-Velez, Himabindu Lakkaraju<br />
			      <i></i> AAAI/ACM Conference on AI, Society, and Ethics (AIES), 2022.<br />
			      <a href="https://dl.acm.org/doi/10.1145/3514094.3534198" class="btn btn-xs btn-default">pdf</a>
		      </p>  
	      </li>
	      <li>
		      <p> A Human-Centric Take on Model Monitoring. <br />
			      Murtuza N Shergadwala, Himabindu Lakkaraju, Krishnaram Kenthapadi <br />
			      <i></i> AAAI Conference on Human Computation and Crowdsourcing (HCOMP), 2022.<br />
			      <a href="https://arxiv.org/pdf/2206.02868.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>  
	      </li>
	      <li>
		      <p> Towards the Unification and Robustness of Post hoc Explanation Methods. <br />
			      Sushant Agarwal, Shahin Jabbari, Chirag Agarwal<sup>*</sup>, Sohini Upadhyay<sup>*</sup>, Steven Wu, Himabindu Lakkaraju <br />
			      <i></i>Symposium on Foundations of Responsible Computing (FORC), 2022. <br />
			      <a href="https://arxiv.org/pdf/2102.10618.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>    
	      </li>
	      <li>
		      <p> Towards Robust and Reliable Algorithmic Recourse. <br />
			      Sohini Upadhyay<sup>*</sup>, Shalmali Joshi<sup>*</sup>, Himabindu Lakkaraju <br />
			      <i></i>Advances in Neural Information Processing Systems (NeurIPS), 2021.<br />
			      <font color="#cc0000">Best Paper Runner Up</font>, ICML Workshop on Algorithmic Recourse, 2021. <br />
                      	      <a href="https://arxiv.org/pdf/2102.13620.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
	     
	      <li>
		      <p> Reliable Post hoc Explanations: Modeling Uncertainty in Explainability. <br />
			      Dylan Slack, Sophie Hilgard, Sameer Singh, Himabindu Lakkaraju <br />
			      <i></i>Advances in Neural Information Processing Systems (NeurIPS), 2021.<br />
                      	      <a href="https://arxiv.org/pdf/2008.05030.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>  
	      <li>
		      <p> Counterfactual Explanations Can Be Manipulated <br />
			      Dylan Slack, Sophie Hilgard, Himabindu Lakkaraju, Sameer Singh <br />
			      <i></i>Advances in Neural Information Processing Systems (NeurIPS), 2021.<br />
                      	      <a href="https://arxiv.org/pdf/2106.02666.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
	      <li>
		      <p> Learning Models for Algorithmic Recourse <br />
			      Alexis Ross, Himabindu Lakkaraju, Osbert Bastani <br />
			      <i></i>Advances in Neural Information Processing Systems (NeurIPS), 2021.<br />
                      	      <a href="https://arxiv.org/pdf/2011.06146.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
	      <li> 
		      <p> Towards the Unification and Robustness of Perturbation and Gradient Based Explanations. <br />
			      Sushant Agarwal, Shahin Jabbari, Chirag Agarwal<sup>*</sup>, Sohini Upadhyay<sup>*</sup>, Steven Wu, Himabindu Lakkaraju <br />
			      <i></i>International Conference on Machine Learning (ICML), 2021.<br />
			      <a href="https://arxiv.org/pdf/2102.10618.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
	      <li> 
		      <p> Towards a Unified Framework for Fair and Stable Graph Representation Learning. <br />
			      Chirag Agarwal, Himabindu Lakkaraju<sup>*</sup>, Marinka Zitnik<sup>*</sup> <br />
			      <i></i>Conference on Uncertainty in Artificial Intelligence (UAI), 2021.<br />
			      <a href="https://arxiv.org/pdf/2102.13186.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
	      <li> 
		      <p> Fair influence maximization: A welfare optimization approach. <br />
			      Aida Rahmattalabi, Shahin Jabbari, Himabindu Lakkaraju, Phebe Vayanos, Eric Rice, Milind Tambe <br />
			      <i></i> AAAI International Conference on Artificial Intelligence (AAAI), 2021.<br />
			      <a href="https://arxiv.org/pdf/2006.07906.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
              <li> 
		      <p> Does Fair Ranking Improve Minority Outcomes? Understanding the Interplay of Human and Algorithmic Biases in Online Hiring. <br />
			      Tom Suhr, Sophie Hilgard, Himabindu Lakkaraju <br />
			      <i></i>AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AIES), 2021.<br />
			      <a href="https://arxiv.org/pdf/2012.00423.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
	  <li>
              <p> Beyond Individualized Recourse: Interpretable and Interactive Summaries of Actionable Recourses <br />
                  Kaivalya Rawal and Himabindu Lakkaraju. <br />
      <i></i>Advances in Neural Information Processing Systems (NeurIPS), 2020.<br />
                  <a href="https://arxiv.org/abs/2009.07165" class="btn btn-xs btn-default">pdf</a>
              </p>
          </li>
	  <li>
              <p> Incorporating Interpretable Output Constraints in Bayesian Neural Networks <br />
                  Wanqian Yang, Lars Lorch, Moritz Gaule, Himabindu Lakkaraju, Finale Doshi-Velez. <br />
      <i></i>Advances in Neural Information Processing Systems (NeurIPS), 2020.<br />
		  <font color="#cc0000"> Spotlight Presentation [Top 3%] </font> <br />
                  <a href="https://arxiv.org/pdf/2010.10969.pdf" class="btn btn-xs btn-default">pdf</a> <br />
              </p>
	  </li>
          <li>
              <p> Robust and Stable Black Box Explanations. <br />
                  Himabindu Lakkaraju, Nino Arsov, Osbert Bastani. <br />
      <i></i>International Conference on Machine Learning (ICML), 2020.<br />
                  <a href="https://proceedings.icml.cc/static/paper_files/icml/2020/5945-Paper.pdf" class="btn btn-xs btn-default">pdf</a>
              </p>
          </li>
          <li>
              <p> Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods. <br />
                  Dylan Slack, Sophie Hilgard, Emily Jia, Sameer Singh, Himabindu Lakkaraju. <br />
		  <i></i>AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AIES), 2020.<br />
		  <font color="#cc0000"> Oral Presentation </font> <br />
                  <a href="https://arxiv.org/pdf/1911.02508.pdf" class="btn btn-xs btn-default">pdf</a> <br />
		  Press: <a href="https://blog.deeplearning.ai/blog/the-batch-sony-goes-ai-intels-gpu-killers-transformer-networks-in-disguise-malicious-models-fool-bias-detection">deeplearning.ai</a> | 
		      <a href="https://hbr.org/2019/12/the-ai-transparency-paradox">Harvard Business Review</a>
              </p>
          </li>
	  <li>
              <p> "How do I fool you?": Manipulating User Trust via Misleading Black Box Explanations. <br />
                  Himabindu Lakkaraju, Osbert Bastani. <br />
		  <i></i>AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AIES), 2020.<br />
		  <font color="#cc0000"> Oral Presentation </font> <br />
                  <a href="https://arxiv.org/pdf/1911.06473.pdf" class="btn btn-xs btn-default">pdf</a>
	      </p>  
          </li>
        <li>
        <p>Faithful and Customizable Explanations of Black Box Models.<br />
           Himabindu Lakkaraju, Ece Kamar, Rich Carauna, Jure Leskovec.<br />
           <i></i>AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AIES), 2019.<br />
           <font color="#cc0000"> Oral Presentation </font> <br />
           <a href="./customizable.pdf" class="btn btn-xs btn-default">pdf</a>
        </p>
        </li>
	<li><p>Human Decisions and Machine Predictions.<br />
	    Jon Kleinberg, Himabindu Lakkaraju, Jure Leskovec, Jens Ludwig, Sendhil Mullainathan.<br />
	    <i>Quarterly Journal of Economics (QJE)</i>, 2018.<br />	
	    <heavy>Featured in MIT Technology Review, Harvard Business Review, The New York Times,</heavy><br />   
	    <heavy>and as Research Spotlight on National Bureau of Economics front page</heavy>.<br />   
	    <a href="https://academic.oup.com/qje/article/doi/10.1093/qje/qjx032/4095198/Human-Decisions-and-Machine-Predictions#" class="btn btn-xs btn-default">pdf</a>  
	</p></li>
	
        <li><p>The Selective Labels Problem: Evaluating Algorithmic Predictions in the Presence of Unobservables.<br />
	    Himabindu Lakkaraju, Jon Kleinberg, Jure Leskovec, Jens Ludwig, Sendhil Mullainathan. <br />
	    <i>ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)</i>, 2017. <br/>
	    <font color="#cc0000"> Oral Presentation </font> <br />
	    <a href="http://cs.stanford.edu/~jure/pubs/contraction-kdd17.pdf" class="btn btn-xs btn-default">pdf</a>
	</p></li>

        <li><p>Learning Cost-Effective and Interpretable Treatment Regimes.<br />
            Himabindu Lakkaraju, Cynthia Rudin.<br />
	    <i>International Conference on Artificial Intelligence and Statistics (AISTATS)</i>, 2017.<br />
	    <font color="#cc0000">INFORMS Data Mining Best Paper Award </font>.<br /> 
	    <heavy>Invited Talk at INFORMS Annual Meeting</heavy>.<br />   
            <a href="https://arxiv.org/abs/1610.06972" class="btn btn-xs btn-default">pdf</a>
            
        </p></li>
	
        <li><p>Identifying Unknown Unknowns in the Open World: Representations and Policies for Guided Exploration.<br />
            Himabindu Lakkaraju, Ece Kamar, Rich Caruana, Eric Horvitz.<br />
            <i>AAAI Conference on Artificial Intelligence (AAAI)</i>, 2017.<br />
            <heavy>Featured in Bloomberg Technology</heavy>.<br />
            <a href="https://arxiv.org/abs/1610.09064" class="btn btn-xs btn-default">pdf</a>
            
        </p></li>
	
        <li><p> Interpretable and Explorable Approximations of Black Box Models.<br />
            Himabindu Lakkaraju, Ece Kamar, Rich Caruana, Jure Leskovec.<br />
            <i>KDD Workshop on Fairness, Accountability, and Transparency in Machine Learning (FAT ML)</i>, 2017.<br />
            <heavy>Invited Talk at INFORMS Annual Meeting</heavy>.<br />   
            <a href="https://arxiv.org/abs/1707.01154" class="btn btn-xs btn-default">pdf</a>
        </p></li>
        
        <li><p>Confusions over Time: An Interpretable Bayesian Model to Characterize Trends in Decision Making.<br />
            Himabindu Lakkaraju, Jure Leskovec.<br />
            <i>Advances in Neural Information Processing Systems (NIPS)</i>, 2016. <br/>
            <a href="https://snap.stanford.edu/hima/paper-temporal-confusions.pdf" class="btn btn-xs btn-default">pdf</a>
        </p></li>
        
        <li><p>Interpretable Decision Sets: A Joint Framework for Description and Prediction.<br />
            Himabindu Lakkaraju, Stephen H. Bach, Jure Leskovec. <br />
            <i>ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)</i>, 2016. <br/>
            <heavy>Invited Talk at INFORMS Annual Meeting</heavy>.<br />   
            <a href="https://cs.stanford.edu/people/jure/pubs/interpretable-kdd16.pdf" class="btn btn-xs btn-default">pdf</a>	  
        </p></li>
        
        <li><p> Mining Big Data to Extract Patterns and Predict Real-Life Outcomes. <br />
            Michal Kosinki, Yilun Wang, Himabindu Lakkaraju, Jure Leskovec.<br />
            <i>Psychological Methods</i>, 2016.<br />
            <a href="http://mypersonality.org/wiki/lib/exe/fetch.php?media=psychological_methods.pdf" class="btn btn-xs btn-default">pdf</a>  
        </p></li>
        
        <li><p>Learning Cost-Effective and Interpretable Regimes for Treatment Recommendation.<br />
            Himabindu Lakkaraju, Cynthia Rudin.<br />
            <i>NIPS Workshop on Interpretable Machine Learning in Complex Systems</i>, 2016.<br />
            <a href="https://arxiv.org/pdf/1611.07663.pdf" class="btn btn-xs btn-default">pdf</a>
        </p></li>
        
        <li><p>Learning Cost-Effective and Interpretable Treatment Regimes for Judicial Bail Decisions. <br />
	    Himabindu Lakkaraju, Cynthia Rudin. <br />
	    <i>NIPS Symposium on Machine Learning and the Law</i>, 2016.<br />
	    <a href="http://www.mlandthelaw.org/papers/lakkaraju.pdf" class="btn btn-xs btn-default">pdf</a>	  
	</p></li>

	<li><p>Discovering Unknown Unknowns of Predictive Models.<br />
	    Himabindu Lakkaraju, Ece Kamar, Rich Caruana, Eric Horvitz.<br />
	    <i>NIPS Workshop on Reliable Machine Learning in the Wild</i>, 2016.<br />
	    <a href="http://web.stanford.edu/~himalv/unknownunknownsws.pdf" class="btn btn-xs btn-default">pdf</a>
	</p></li>

	<li><p>A Machine Learning Framework to Identify Students at Risk of Adverse Academic Outcomes. <br />
	    Himabindu Lakkaraju, Everaldo Aguiar, Carl Shan, David Miller, Nasir Bhanpuri, Rayid Ghani. <br />
	    <i>ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)</i>, 2015.<br />
            <font color="#cc0000"> Oral Presentation </font> <br />
	    <a href="http://dssg.uchicago.edu/papers/montgomery_education.pdf" class="btn btn-xs btn-default">pdf</a>	
	</p></li>

	<li><p>A Bayesian Framework for Modeling Human Evaluations. <br />
	    Himabindu Lakkaraju, Jure Leskovec, Jon Kleinberg, Sendhil Mullainathan. <br />
	    <i>SIAM International Conference on Data Mining (SDM) </i>, 2015.<br />
	   <font color="#cc0000"> Oral Presentation </font> <br />
	    <a href="http://cs.stanford.edu/people/jure/pubs/evaluations-sdm15.pdf" class="btn btn-xs btn-default">pdf</a>  
	</p></li>

	<li><p>Who, When, and Why: A Machine Learning Approach to Prioritizing Students at Risk of not Graduating High School on Time.<br />
	    Everaldo Aguiar, Himabindu Lakkaraju, Nasir Bhanpuri, David Miller, Ben Yuhas, Kecia Addison, Rayid Ghani.
<br />
	    <i>Learning Analytics and Knowledge Conference (LAK)</i>, 2015.<br />
	    <a href="http://dl.acm.org/citation.cfm?id=2723619" class="btn btn-xs btn-default">pdf</a>
	</p></li>

	<!-- <li><p>Aspect Specific Sentiment Analysis using Hierarchical Deep Learning.<br />
	    Himabindu Lakkaraju, Richard Socher, Chris Manning.<br />
	    <i>NIPS Workshop on Deep Learning and Representation Learning</i>, 2014.<br />
	    <a href="http://www.dlworkshop.org/58.pdf?attredirects=0" class="btn btn-xs btn-default">pdf</a>  	  
	</p></li>

	<li><p>Using Big Data to Improve Social Policy.<br />
	    Jon Kleinberg, Himabindu Lakkaraju, Jure Leskovec, Jens Ludwig, Sendhil Mullainathan.<br />
	    <i>NBER Economics of Crime Working Group</i>, 2014.<br />
	    <a href="https://academic.oup.com/qje/article/doi/10.1093/qje/qjx032/4095198/Human-Decisions-and-Machine-Predictions#" class="btn btn-xs btn-default">pdf</a>  	  
	</p></li> -->

	<li><p>What's in a name ? Understanding the Interplay Between Titles, Content, and Communities in Social Media.<br />
	    Himabindu Lakkaraju, Julian McAuley, Jure Leskovec. <br />
	    <i>International AAAI Conference on Weblogs and Social Media (ICWSM)</i>, 2013.<br />
	    <font color="#cc0000"> Oral Presentation </font> <br />
	    <heavy>Featured in Time, Forbes, Phys.Org, Business Insider</heavy>.<br />
	    <a href="https://sites.google.com/site/himabindulv/papers/ICWSM2013.pdf?attredirects=0" class="btn btn-xs btn-default">pdf</a>  	  
	</p></li>

	<li><p>Dynamic Multi-Relational Chinese Restaurant Process for Analyzing Influences on Users in Social Media.<br />
	    Himabindu Lakkaraju, Indrajit Bhattacharya, Chiranjib Bhattacharyya.<br />
	    <i>IEEE International Conference on Data Mining (ICDM)</i>, 2012.<br />
	    <font color="#cc0000"> Oral Presentation </font> <br />
	    <a href="http://arxiv.org/abs/1205.1456" class="btn btn-xs btn-default">pdf</a>  	  
	</p></li>
	<li><p>TEM: a novel perspective to modeling content on microblogs.<br />
	    Himabindu Lakkaraju, Hyung-Il Ahn.<br />
	    <i>International World Wide Web Conference (WWW), short paper</i>, 2012.<br />
	    <a href="http://www2012.wwwconference.org/proceedings/companion/p553.pdf" class="btn btn-xs btn-default">pdf</a>  	  
	</p></li>
	<li><p>Exploiting Coherence for the Simultaneous Discovery of Latent Facets and associated Sentiments.<br />
	    Himabindu Lakkaraju, Chiranjib Bhattacharyya, Indrajit Bhattacharya, Srujana Merugu.<br />
	    <i>SIAM International Conference on Data Mining (SDM)</i>, 2011.<br />
	    <font color="#cc0000">Best Paper Award</font>.<br />
	    <a href="https://sites.google.com/site/himabindulv/papers/324.pdf?attredirects=0" class="btn btn-xs btn-default">pdf</a>  	  
	</p></li>
	<li><p>Attention prediction on social media brand pages.<br />
	    Himabindu Lakkaraju, Jitendra Ajmera.<br />
	    <i>ACM Conference on Information and Knowledge Management (CIKM)</i>, 2011.<br />
	    <a href="https://sites.google.com/site/himabindulv/papers/cikm0226-lakkaraju.pdf?attredirects=0" class="btn btn-xs btn-default">pdf</a>  	  
	</p></li>
	<li><p>Smart news feeds for social networks using scalable joint latent factor models.<br />
	    Himabindu Lakkaraju, Angshu Rai, Srujana Merugu.<br />
	    <i>International World Wide Web Conference (WWW), short paper</i>, 2011.<br />
	    <a href="https://sites.google.com/site/himabindulv/papers/smartnewsfeeds1.pdf?attredirects=0" class="btn btn-xs btn-default">pdf</a>  	  
	</p></li>
	<!--<li><p>A Non Parametric Theme Event Topic Model for Characterizing Microblogs.<br />
	    Himabindu Lakkaraju, Hyung-Il Ahn. <br />
	    <i>NIPS Workshop on Computational Social Science and the Wisdom of Crowds</i>, 2011.<br />
	    <a href="https://sites.google.com/site/himabindulv/papers/themeevent-final.pdf?attredirects=0" class="btn btn-xs btn-default">pdf</a>  	  
	</p></li>
	<li><p>Unified Modeling of User Activities on Social Networking Sites.<br />
	    Himabindu Lakkaraju, Angshu Rai. <br />
	    <i>NIPS Workshop on Computational Social Science and the Wisdom of Crowds</i>, 2011.<br />
	    <a href="https://sites.google.com/site/himabindulv/papers/unifiedmodeling-final.pdf?attredirects=0" class="btn btn-xs btn-default">pdf</a>  	  
	</p></li>-->
      </ul>
      </font>

      <h4>Patents</h4>
      <font size="3">
      <ul>
	<li><p>Extraction and Grouping of Feature Words.<br />
	    Himabindu Lakkaraju, Chiranjib Bhattacharyya, Sunil Aravindam, Kaushik Nath.<br />
	    US8484228<br />
	</p></li>
	<li><p>Enhancing knowledge bases using rich social media.<br />
	    Jitendra Ajmera, Shantanu Ravindra Godbole, Himabindu Lakkaraju, Bernard Andrew Roden, Ashish Verma. <br />
	    US20130224714<br />
	</p></li>
      </ul>	 
      </font>
		
    <div class="page-header" id="students"> <h3>Advising</h3> </div>
		
    		<p>I am very fortunate to be working with the following core group of students, interns, postdocs, and research affiliates</p>
		<p>
		<ul>
			<li style="font-weight:normal">Suraj Srinivas (Postdoc, Harvard University)</li>
			<li style="font-weight:normal">Jiaqi Ma (Postdoc, Harvard University)</li>
			<li style="font-weight:normal">Abhi Dubey (Research Scientist, Facebook AI Research; Research Affiliate, Harvard University)</li>
			<li style="font-weight:normal">Chirag Agarwal (Research Scientist, Adobe Research; Research Affiliate, Harvard University)</li>
			<li style="font-weight:normal">Satyapriya Krishna (PhD Student, Harvard University)</li>
			<li style="font-weight:normal">Tessa Han (PhD Student, Harvard University)</li>
			<li style="font-weight:normal">Dan Ley (PhD Student, Harvard University)</li>
			<li style="font-weight:normal">Usha Bhalla (PhD Student, Harvard University); Co-advised with Hanspeter Pfister </li>
			<li style="font-weight:normal">Alex Oesterling (PhD Student, Harvard University); Co-advised with Flavio Calmon </li>
			<li style="font-weight:normal">Paul Hamilton (PhD Student, Harvard University)</li>
			<li style="font-weight:normal">Dylan Slack (PhD Student, UC Irvine); Co-advised with Sameer Singh</li>
			<li style="font-weight:normal">Isha Puri (Undergrad, Harvard University)</li>
			<li style="font-weight:normal">Eshika Saxena (Undergrad, Harvard University)</li>
			<br>
			<li style="font-weight:normal">Martin Pawelczyk (PhD Student, University of Tubingen; Research Fellow, Harvard University)</li>
			<li style="font-weight:normal">Umang Bhatt (PhD Student, University of Cambridge; Research Intern, Harvard University)</li>
			<li style="font-weight:normal">Davor Ljubenkov (Fullbright Scholar; Research Fellow, Harvard University)</li>
		</ul>
		</p>
	    	<p> <b>Alumni</b> (Past Advisees, Close Collaborators, and Visitors): </p>
		<p>
	    	<ul>
			<li style="font-weight:normal">Chirag Agarwal (Postdoc, Harvard University --> Research Scientist, Adobe Research)</li>
			<li style="font-weight:normal">Alexis Ross (Undergraduate Student, Harvard University --> MIT EECS PhD, Winner of Hoopes Prize for Best Undergrad Thesis)</li>
			<li style="font-weight:normal">Kaivalya Rawal (Masters Student, Harvard University --> Fiddler AI)</li>
			<li style="font-weight:normal">Aditya Karan (Masters Student, Harvard University --> PhD Student, UIUC)</li>
			<li style="font-weight:normal">Jessica Dai (Undergraduate Student, Brown University --> UC Berkeley EECS PhD) </li>	
			<li style="font-weight:normal">Ethan Kim (Undergraduate Student, Harvard University --> Cyndx) </li>
			<br>
			<li style="font-weight:normal">Shahin Jabbari (CRCS Postdoctoral Fellow, Harvard University --> Assistant Professor, Drexel University)</li>
			<li style="font-weight:normal">Sophie Hilgard (PhD Student, Harvard University --> Research Scientist, Twitter) </li>
			<li style="font-weight:normal">Sushant Agarwal (Masters Student, University of Waterloo --> PhD Student, Northeastern University) </li>
			<br>
			<li style="font-weight:normal">Harvineet Singh (PhD Student, New York University; Research Intern, Harvard University) </li>	
			<li style="font-weight:normal">Elita Lobo (PhD Student, UMass Amherst; Research Intern, Harvard University) </li>
			<li style="font-weight:normal">Anna Meyer (PhD Student, University of Wisconsin; Research Intern, Harvard University)</li>
			<li style="font-weight:normal">Ruijiang Gao (PhD Student, University of Texas at Austin; Research Intern, Harvard University)</li>
			<li style="font-weight:normal">Vishwali Mhasawade (PhD Student, New York University; Research Intern, Harvard University)</li>
			<li style="font-weight:normal">Tom Suhr (PhD Student, Max Planck Institute; Research Fellow, Harvard University) </li>
			
			
		</ul>
		</p>
    <div class="page-header" id="teaching"><h3>Teaching</h3></div>
     <font size="3">
	     
      <ul>
	<li><p> <a href="https://interpretable-ml-class.github.io/">Topics in Machine Learning: Interpretability and Explainability</a><br/>
	        Instructor <br />
		<i>Harvard University</i>, 2023.<br />
	</p></li>
	<li><p> <a href="https://hbs.instructure.com/courses/7791">Introduction to Technology and Operations Management</a><br/>
	        Instructor <br />
		<i>Harvard University</i>, 2022.<br />
	</p></li>
	<li><p> <a href="https://interpretable-ml-class.github.io/">Topics in Machine Learning: Interpretability and Explainability</a><br/>
	        Instructor <br />
		<i>Harvard University</i>, 2021.<br />
	</p></li>
	<li><p> <a href="https://hbs.instructure.com/courses/7791">Introduction to Technology and Operations Management</a><br/>
	        Instructor <br />
		<i>Harvard University</i>, 2020.<br />
	</p></li>
	<li><p> <a href="https://hbs.instructure.com/courses/6256">Introduction to Machine Learning for Social Scientists</a><br/>
	        Instructor <br />
		<i>Harvard University</i>, 2020.<br />
	</p></li>
	<li><p> <a href="https://interpretable-ml-class.github.io/">Topics in Machine Learning: Interpretability and Explainability</a><br/>
	        Instructor <br />
		<i>Harvard University</i>, 2019.<br />
	</p></li>
	<li><p>Introduction to Data Science<br />
	    Guest Lecture<br />
	    <i>Stanford Law School</i>, 2016.<br />	 
	</p></li>
	<li><p>Probability with Mathemagic<br />
	    Co-Instructor<br />
	    <i>Stanford Splash Initiative for High School Students</i>, 2016.<br />	 
	</p></li>
	<li><p>Mining Massive Datasets Course<br />
	    Teaching Assistant<br />
	    <i>Stanford Computer Science</i>, 2016.<br />	 
	</p></li>
	<li><p>Submodular Optimization<br />
	    Guest Lecture<br />
	    <i>Mining Massive Datasets Course, Stanford</i>, 2016.<br />	 
	</p></li>
	<li><p>Introduction to Python Programming<br />
	    Co-Instructor<br />
	    <i>Stanford Girls Teaching Girls to Code Initiative for High School Students</i>, 2015.<br />	 
	</p></li>
	<li><p>Mathematics and Science<br />
	    Tutor<br />
	    <i>Dreamcatchers Non-Profit Organization, Palo Alto</i>, 2015.<br />	 
	</p></li>
	<li><p>Social and Information Network Analysis Course<br />
	    Head Teaching Assistant<br />
	    <i>Stanford Computer Science</i>, 2014.<br />	 
	</p></li>
	<li><p>Machine Learning Course<br />
	    Teaching Assistant<br />
	    <i>Indian Institute of Science</i>, 2010.<br />	 
	</p></li>
	<li><p>English and Mathematics<br />
	    Tutor<br />
	    <i>UNICEF's Teach India Initiative</i>, 2008 - 2010.<br />	 
	</p></li>
	<li><p>Object Oriented Programming<br />
	    Co-Instructor<br />
	    <i>Visvesvaraya Technological University</i>, 2007.<br />	 
	</p></li>
	<li><p>Introduction to Databases<br />
	    Co-Instructor<br />
	    <i>Visvesvaraya Technological University</i>, 2007.<br />	 
	</p></li>
	</ul>
	</font>
    </div> <!-- /container -->


    <!-- Bootstrap core JavaScript
	 ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')</script>
      <script src="js/bootstrap.min.js"></script>
      <script src="js/docs.min.js"></script>
      <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
      <script src="js/ie10-viewport-bug-workaround.js"></script>
  </body>
</html>
